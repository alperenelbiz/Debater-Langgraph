{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf13188",
   "metadata": {},
   "source": [
    "# Debate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2f6bf",
   "metadata": {},
   "source": [
    "## Required Environment Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547d33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import gradio as gr\n",
    "import html\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Any, Optional, TypedDict, Literal, Dict\n",
    "from IPython.display import Image\n",
    "from typing import Tuple\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.tools import tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8ade7",
   "metadata": {},
   "source": [
    "## Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4866998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84993151",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c354c",
   "metadata": {},
   "source": [
    "##  Debate State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46879adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebateMessage(TypedDict):\n",
    "    role: Literal[\"debater1\", \"debater2\", \"judge\", \"tools\"]\n",
    "    content: str\n",
    "\n",
    "class DebateState(TypedDict, total=False):\n",
    "    topic: str\n",
    "    round: int\n",
    "    max_rounds: int\n",
    "    messages: List[DebateMessage]\n",
    "    winner: Optional[str]\n",
    "    verdict: Optional[str]\n",
    "    tool_caller: Optional[Literal[\"debater1\", \"debater2\"]]\n",
    "    pending_tool_calls: Optional[List[Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130cd35",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fedafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper(\n",
    "    serper_api_key=SERPER_API_KEY,\n",
    "    gl=\"us\",   # geographic location\n",
    "    hl=\"en\",   # interface language\n",
    "    k=5        # number of results to consider\n",
    ") if SERPER_API_KEY else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb3c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_serper_results(res: dict) -> str:\n",
    "    items = []\n",
    "    organic = res.get(\"organic\", []) or res.get(\"results\", []) or []\n",
    "\n",
    "    for r in organic:\n",
    "        title = r.get(\"title\") or r.get(\"titleHighlighted\") or \"Untitled\"\n",
    "        link = r.get(\"link\") or r.get(\"url\") or \"\"\n",
    "        snippet = r.get(\"snippet\") or r.get(\"snippetHighlighted\") or \"\"\n",
    "        source = r.get(\"source\") or r.get(\"domain\") or \"\"\n",
    "        \n",
    "        if not source and link:\n",
    "            try:\n",
    "                from urllib.parse import urlparse\n",
    "                source = urlparse(link).netloc\n",
    "            except Exception:\n",
    "                source = \"\"\n",
    "\n",
    "        title = (title[:120] + \"…\") if len(title) > 120 else title\n",
    "        snippet = (snippet[:200] + \"…\") if len(snippet) > 200 else snippet\n",
    "        items.append(f\"- {title} [{source}]\\n  {snippet}\")\n",
    "\n",
    "    if not items:\n",
    "        return \"No relevant results.\"\n",
    "\n",
    "    return \"Search summary:\\n\" + \"\\n\".join(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74fcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web using Google Serper and return a compact textual summary.\"\"\"\n",
    "    if not query or not isinstance(query, str):\n",
    "        return \"No query provided.\"\n",
    "    try:\n",
    "        res = serper.results(query)\n",
    "        return _format_serper_results(res)\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc0e40",
   "metadata": {},
   "source": [
    "### Tool Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89561eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS: List[Any] = [web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21b48967",
   "metadata": {},
   "outputs": [],
   "source": [
    "debater1_llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.7)\n",
    "debater2_llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.7)\n",
    "judge_llm   = ChatOpenAI(model=OPENAI_MODEL, temperature=0.1)\n",
    "\n",
    "debater1_llm_with_tools = debater1_llm.bind_tools(TOOLS)\n",
    "debater2_llm_with_tools = debater2_llm.bind_tools(TOOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4bfab9",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01368e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_transcript(messages: List[DebateMessage]) -> str:\n",
    "    lines = []\n",
    "    \n",
    "    for m in messages:\n",
    "        lines.append(f\"{m['role'].upper()}: {m['content']}\")\n",
    "    return \"\\n\".join(lines) if lines else \"(no prior messages)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f0b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_return_from_tools(state: DebateState, role: Literal[\"debater1\", \"debater2\"]) -> bool:\n",
    "    if not state.get(\"messages\"):\n",
    "        return False\n",
    "\n",
    "    last = state[\"messages\"][-1][\"role\"]\n",
    "    \n",
    "    return last == \"tools\" and state.get(\"tool_caller\") == role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae2a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_judge_json(raw_text: str) -> Tuple[str, str]:\n",
    "    try:\n",
    "        data = json.loads(raw_text)\n",
    "        w = data.get(\"winner\", \"draw\")\n",
    "        v = data.get(\"verdict\", \"\")\n",
    "\n",
    "        if w not in (\"debater1\", \"debater2\", \"draw\"):\n",
    "            w = \"draw\"\n",
    "\n",
    "        if not isinstance(v, str):\n",
    "            v = str(v)\n",
    "\n",
    "        return w, v\n",
    "        \n",
    "    except Exception:\n",
    "        return \"draw\", raw_text.strip() or \"No structured verdict provided.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59165b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_inputs(topic: str, max_rounds: int):\n",
    "    if not isinstance(topic, str) or not topic.strip():\n",
    "        raise ValueError(\"Topic must be a non-empty string.\")\n",
    "\n",
    "    if not isinstance(max_rounds, int) or max_rounds < 1:\n",
    "        raise ValueError(\"max_rounds must be an integer >= 1.\")\n",
    "\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        raise EnvironmentError(\"OPENAI_API_KEY is not set in the environment.\")\n",
    "        \n",
    "    if not os.getenv(\"SERPER_API_KEY\"):\n",
    "        print(\"Warning: SERPER_API_KEY is not set; web_search tool will return a configuration message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e15972a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_state(topic: str, max_rounds: int) -> DebateState:\n",
    "    return {\n",
    "        \"topic\": topic,\n",
    "        \"round\": 0,\n",
    "        \"max_rounds\": max_rounds,\n",
    "        \"messages\": [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79c5a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_transcript(state: DebateState):\n",
    "    print(\"\\n=== Debate Transcript ===\")\n",
    "    \n",
    "    visible_idx = 1\n",
    "    last_judge_text = None\n",
    "\n",
    "    for m in state.get(\"messages\", []):\n",
    "        role = m.get(\"role\")\n",
    "        content = (m.get(\"content\") or \"\").strip()\n",
    "\n",
    "        if role in (\"debater1\", \"debater2\"):\n",
    "            if content.startswith(\"[REQUEST_TOOLS]\"):\n",
    "                continue\n",
    "            speaker = \"Debater1\" if role == \"debater1\" else \"Debater2\"\n",
    "            print(f\"{visible_idx:02d}. {speaker}: {content}\")\n",
    "            visible_idx += 1\n",
    "\n",
    "        elif role == \"judge\":\n",
    "            last_judge_text = content\n",
    "\n",
    "    if last_judge_text:\n",
    "        print(\"\\n--- Judge's Verdict ---\")\n",
    "        print(last_judge_text)\n",
    "\n",
    "    print(\"=========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562b648",
   "metadata": {},
   "source": [
    "## Role Prompts and JSON Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce93b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBATER1_SYSTEM_PROMPT = \"\"\"\n",
    "You are Debater1 in a structured debate.\n",
    "Goals:\n",
    "- Present strong arguments supporting your side.\n",
    "- Be clear, concise, and logically sound.\n",
    "- If you need any external facts (statistics, dates, definitions, named sources, recent events),\n",
    "  you must first call the tool `web_search` with a concise query and then incorporate those results.\n",
    "- If no external facts are needed, respond directly without tools.\n",
    "Only use information available in the transcript or via tools you explicitly call.\n",
    "\"\"\"\n",
    "\n",
    "DEBATER2_SYSTEM_PROMPT = \"\"\"\n",
    "You are Debater2 in a structured debate.\n",
    "Goals:\n",
    "- Rebut Debater1's points and present counterarguments.\n",
    "- Be clear, concise, and logically sound.\n",
    "- If you need any external facts (statistics, dates, definitions, named sources, recent events),\n",
    "  you must first call the tool `web_search` with a concise query and then incorporate those results.\n",
    "- If no external facts are needed, respond directly without tools.\n",
    "Only use information available in the transcript or via tools you explicitly call.\n",
    "\"\"\"\n",
    "\n",
    "JUDGE_SYSTEM_PROMPT = \"\"\"\n",
    "You are the Judge in a structured debate. Your role:\n",
    "- Evaluate both sides on clarity, logic, evidence, and responsiveness to the other side.\n",
    "- Be neutral and objective.\n",
    "- Produce a concise verdict.\n",
    "\n",
    "You must return a single JSON object:\n",
    "{\n",
    "  \"winner\": \"debater1\" | \"debater2\" | \"draw\",\n",
    "  \"verdict\": \"short explanation focusing on reasoning quality and evidence\"\n",
    "}\n",
    "Rules:\n",
    "- Consider only the transcript provided.\n",
    "- Do not include any text outside the single JSON object.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92276e2f",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a68bb",
   "metadata": {},
   "source": [
    "### Debater1 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7b2e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debater1_node(state: DebateState) -> DebateState:\n",
    "    topic = state[\"topic\"]\n",
    "    transcript = render_transcript(state[\"messages\"])\n",
    "\n",
    "    returning = is_return_from_tools(state, \"debater1\")\n",
    "    system_prompt = DEBATER1_SYSTEM_PROMPT\n",
    "    user_prompt = (\n",
    "        f\"Topic: {topic}\\nTranscript so far:\\n{transcript}\\n\\n\"\n",
    "        + (\n",
    "            \"Do not call any tools now. Produce your best final argument for this turn using the tool results above.\"\n",
    "            if returning else\n",
    "            \"Before asserting any external facts, call `web_search` with a concise query. \"\n",
    "            \"If no external facts are required, respond directly.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    llm = debater1_llm if returning else debater1_llm_with_tools\n",
    "    resp = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)])\n",
    "\n",
    "    tool_calls = getattr(resp, \"tool_calls\", None)\n",
    "    if tool_calls and not returning:\n",
    "        request_msg: DebateMessage = {\"role\": \"debater1\", \"content\": \"[REQUEST_TOOLS]\"}\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"messages\": state[\"messages\"] + [request_msg],\n",
    "            \"tool_caller\": \"debater1\",\n",
    "            \"pending_tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "    argument_text = resp.content if isinstance(resp.content, str) else str(resp.content)\n",
    "    new_message: DebateMessage = {\"role\": \"debater1\", \"content\": argument_text}\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state[\"messages\"] + [new_message],\n",
    "        \"tool_caller\": None if returning else state.get(\"tool_caller\"),\n",
    "        \"pending_tool_calls\": None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48ae53",
   "metadata": {},
   "source": [
    "### Debater2 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4ec3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debater2_node(state: DebateState) -> DebateState:\n",
    "    topic = state[\"topic\"]\n",
    "    transcript = render_transcript(state[\"messages\"])\n",
    "\n",
    "    returning = is_return_from_tools(state, \"debater2\")\n",
    "    system_prompt = DEBATER2_SYSTEM_PROMPT\n",
    "    user_prompt = (\n",
    "        f\"Topic: {topic}\\nTranscript so far:\\n{transcript}\\n\\n\"\n",
    "        + (\n",
    "            \"Do not call any tools now. Produce your best final rebuttal for this turn using the tool results above.\"\n",
    "            if returning else\n",
    "            \"Before asserting any external facts, call `web_search` with a concise query. \"\n",
    "            \"If no external facts are required, respond directly.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    llm = debater2_llm if returning else debater2_llm_with_tools\n",
    "    resp = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)])\n",
    "\n",
    "    tool_calls = getattr(resp, \"tool_calls\", None)\n",
    "    \n",
    "    if tool_calls and not returning:\n",
    "        request_msg: DebateMessage = {\"role\": \"debater2\", \"content\": \"[REQUEST_TOOLS]\"}\n",
    "        return {\n",
    "            **state,\n",
    "            \"messages\": state[\"messages\"] + [request_msg],\n",
    "            \"tool_caller\": \"debater2\",\n",
    "            \"pending_tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "    argument_text = resp.content if isinstance(resp.content, str) else str(resp.content)\n",
    "    new_message: DebateMessage = {\"role\": \"debater2\", \"content\": argument_text}\n",
    "\n",
    "    new_round = min(state[\"round\"] + 1, state[\"max_rounds\"])\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"round\": new_round,\n",
    "        \"messages\": state[\"messages\"] + [new_message],\n",
    "        \"tool_caller\": None if returning else state.get(\"tool_caller\"),\n",
    "        \"pending_tool_calls\": None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111a287",
   "metadata": {},
   "source": [
    "### Judge Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719b7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_node(state: DebateState) -> DebateState:\n",
    "    topic = state[\"topic\"]\n",
    "    transcript = render_transcript(state[\"messages\"])\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=JUDGE_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=f\"Topic: {topic}\\nFull transcript:\\n{transcript}\")\n",
    "    ]\n",
    "    resp = judge_llm.invoke(messages)\n",
    "    winner, verdict = parse_judge_json(resp.content)\n",
    "\n",
    "    judge_msg: DebateMessage = {\"role\": \"judge\", \"content\": verdict or \"[No verdict text]\"}\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state[\"messages\"] + [judge_msg],\n",
    "        \"winner\": winner,\n",
    "        \"verdict\": verdict or \"[No verdict text]\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ad15f",
   "metadata": {},
   "source": [
    "### Tools Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b45941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tools_node(state: DebateState) -> DebateState:\n",
    "    pending = state.get(\"pending_tool_calls\") or []\n",
    "    caller = state.get(\"tool_caller\")\n",
    "    tools_by_name: Dict[str, Any] = {t.name: t for t in TOOLS}\n",
    "\n",
    "    results: List[str] = []\n",
    "\n",
    "    for call in pending:\n",
    "        name = call.get(\"name\")\n",
    "        args = call.get(\"args\", {}) or {}\n",
    "        tool_obj = tools_by_name.get(name)\n",
    "        if tool_obj is None:\n",
    "            results.append(f\"[{name}] Tool not found.\")\n",
    "            continue\n",
    "        try:\n",
    "            out = tool_obj.invoke(args)\n",
    "            results.append(f\"[{name}] {out}\")\n",
    "        except Exception as e:\n",
    "            results.append(f\"[{name}] Error: {e}\")\n",
    "\n",
    "    tools_summary = \" | \".join(results) if results else \"[No tools executed]\"\n",
    "    tools_message: DebateMessage = {\"role\": \"tools\", \"content\": tools_summary}\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state[\"messages\"] + [tools_message],\n",
    "        \"pending_tool_calls\": None,\n",
    "        \"tool_caller\": caller,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57f048",
   "metadata": {},
   "source": [
    "## Routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbdd072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_debater1(state: DebateState) -> str:\n",
    "    if state[\"round\"] >= state[\"max_rounds\"]:\n",
    "        return \"judge_node\"\n",
    "\n",
    "    if state.get(\"pending_tool_calls\"):\n",
    "        return \"tools_node\"\n",
    "        \n",
    "    return \"debater2_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1b192c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_debater2(state: DebateState) -> str:\n",
    "    if state.get(\"pending_tool_calls\"):\n",
    "        return \"tools_node\"\n",
    "        \n",
    "    return \"debater1_node\" if state[\"round\"] < state[\"max_rounds\"] else \"judge_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34be60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_tools(state: DebateState) -> str:\n",
    "    caller = state.get(\"tool_caller\")\n",
    "\n",
    "    if caller == \"debater1\":\n",
    "        return \"debater1_node\"\n",
    "\n",
    "    if caller == \"debater2\":\n",
    "        return \"debater2_node\"\n",
    "        \n",
    "    return \"debater1_node\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad813d",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a83a8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(DebateState)\n",
    "graph_builder.add_node(\"debater1_node\", debater1_node)\n",
    "graph_builder.add_node(\"debater2_node\", debater2_node)\n",
    "graph_builder.add_node(\"judge_node\", judge_node)\n",
    "graph_builder.add_node(\"tools_node\", tools_node)\n",
    "\n",
    "graph_builder.set_entry_point(\"debater1_node\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"debater1_node\",\n",
    "    route_after_debater1,\n",
    "    {\n",
    "        \"tools_node\": \"tools_node\",\n",
    "        \"debater2_node\": \"debater2_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"debater2_node\",\n",
    "    route_after_debater2,\n",
    "    {\n",
    "        \"tools_node\": \"tools_node\",\n",
    "        \"debater1_node\": \"debater1_node\",\n",
    "        \"judge_node\": \"judge_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"tools_node\",\n",
    "    route_after_tools,\n",
    "    {\n",
    "        \"debater1_node\": \"debater1_node\",\n",
    "        \"debater2_node\": \"debater2_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"judge_node\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc80518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cbf760",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30201b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_debate(topic: str, max_rounds: int = 2, thread_id: str | None = None, print_result: bool = True) -> DebateState:\n",
    "    _validate_inputs(topic, max_rounds)\n",
    "    state = _init_state(topic, max_rounds)\n",
    "\n",
    "    if thread_id is None:\n",
    "        thread_id = f\"debate-{uuid.uuid4()}\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    final_state = graph.invoke(state, config=config)\n",
    "\n",
    "    assert final_state[\"round\"] == final_state[\"max_rounds\"], \"Debate did not complete all rounds.\"\n",
    "    assert final_state[\"messages\"] and final_state[\"messages\"][-1][\"role\"] == \"judge\", \"Final message must be from judge.\"\n",
    "    assert \"winner\" in final_state and \"verdict\" in final_state, \"Judge outcome missing.\"\n",
    "\n",
    "    if print_result:\n",
    "        _print_transcript(final_state)\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b4cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final = run_debate(\"Is universal basic income a net positive for society?\", max_rounds=2, print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990c958",
   "metadata": {},
   "source": [
    "## Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06b9c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_REQUEST_TOKENS = {\"[REQUEST_TOOLS]\", \"REQUEST_TOOLS\", \"<REQUEST_TOOLS>\", \"[CALL_TOOL]\", \"CALL_TOOL\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf1a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(content: Any) -> str:\n",
    "    if content is None:\n",
    "        return \"\"\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    if isinstance(content, dict):\n",
    "        if \"text\" in content and isinstance(content[\"text\"], str):\n",
    "            return content[\"text\"]\n",
    "        return \"\\n\".join([v for v in content.values() if isinstance(v, str)])\n",
    "    if isinstance(content, list):\n",
    "        parts = []\n",
    "        for ch in content:\n",
    "            if isinstance(ch, dict):\n",
    "                t = ch.get(\"type\")\n",
    "                if t == \"text\" and isinstance(ch.get(\"text\"), str):\n",
    "                    parts.append(ch[\"text\"])\n",
    "                elif t in (\"tool_use\", \"tool_result\", \"function_call\"):\n",
    "                    continue\n",
    "                elif isinstance(ch.get(\"text\"), str):\n",
    "                    parts.append(ch[\"text\"])\n",
    "        return \"\\n\\n\".join(p for p in parts if p)\n",
    "    return str(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2e73a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_tool_request(text: str, msg: Dict[str, Any]) -> bool:\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return True\n",
    "    if t.upper() in TOOL_REQUEST_TOKENS:\n",
    "        return True\n",
    "    if isinstance(msg.get(\"additional_kwargs\"), dict) and msg[\"additional_kwargs\"].get(\"tool_calls\"):\n",
    "        return True\n",
    "    if msg.get(\"tool_calls\") or msg.get(\"function_call\"):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cd19da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_debater(msg: Dict[str, Any]) -> str:\n",
    "    role = str(msg.get(\"role\", \"\") or \"\").lower()\n",
    "    name = str(msg.get(\"name\", \"\") or \"\").lower()\n",
    "    if \"debater1\" in role or \"debater1\" in name:\n",
    "        return \"debater1\"\n",
    "    if \"debater2\" in role or \"debater2\" in name:\n",
    "        return \"debater2\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f00d4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coerce_messages(final_state: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    for key in (\"transcript\", \"messages\", \"history\", \"chat\"):\n",
    "        val = final_state.get(key)\n",
    "        if isinstance(val, list) and val:\n",
    "            return val\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2491297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_chat_messages(transcript: List[Dict[str, Any]]) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Return ordered chat entries like:\n",
    "    [{\"side\":\"left\",\"who\":\"Debater 1\",\"round\":1,\"text\":\"...\"}, ...]\n",
    "    \"\"\"\n",
    "    rounds = {\"debater1\": 0, \"debater2\": 0}\n",
    "    out = []\n",
    "    for m in transcript:\n",
    "        who_key = which_debater(m)\n",
    "        if not who_key:\n",
    "            continue\n",
    "        text = extract_text(m.get(\"content\"))\n",
    "        if looks_like_tool_request(text, m):\n",
    "            continue\n",
    "        rounds[who_key] += 1\n",
    "        out.append({\n",
    "            \"side\": \"left\" if who_key == \"debater1\" else \"right\",\n",
    "            \"who\": \"Debater 1\" if who_key == \"debater1\" else \"Debater 2\",\n",
    "            \"round\": str(rounds[who_key]),\n",
    "            \"text\": text\n",
    "        })\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c741bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_chat_html(entries: List[Dict[str, str]]) -> str:\n",
    "    items = []\n",
    "    for e in entries:\n",
    "        txt = html.escape(e[\"text\"]).replace(\"\\n\", \"<br>\")\n",
    "        who = e[\"who\"]\n",
    "        rnd = e[\"round\"]\n",
    "        side_class = \"left\" if e[\"side\"] == \"left\" else \"right\"\n",
    "        bubble_class = \"bubble-left\" if side_class == \"left\" else \"bubble-right\"\n",
    "        items.append(f\"\"\"\n",
    "        <div class=\"msg-row {side_class}\">\n",
    "          <div class=\"msg-bubble {bubble_class}\">\n",
    "            <div class=\"msg-meta\">{who} — Round {rnd}</div>\n",
    "            <div class=\"msg-text\">{txt or \"<i>(no message)</i>\"}</div>\n",
    "          </div>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "      .chat-wrap { display:flex; flex-direction:column; gap:10px; }\n",
    "      .msg-row { display:flex; width:100%; }\n",
    "      .msg-row.left { justify-content:flex-start; }\n",
    "      .msg-row.right { justify-content:flex-end; }\n",
    "\n",
    "      .msg-bubble {\n",
    "        max-width: 78%;\n",
    "        padding: 10px 12px;\n",
    "        border: 1px solid #00000022;\n",
    "        box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
    "        color: #000 !important;\n",
    "      }\n",
    "      .msg-text { color:#000 !important; line-height:1.6; }\n",
    "      .msg-meta { font-weight:700; font-size: 0.9rem; margin-bottom:6px; color:#000 !important; }\n",
    "\n",
    "      .bubble-left {\n",
    "        background: #fff4c2;\n",
    "        border-radius: 14px 14px 14px 4px;\n",
    "      }\n",
    "      .bubble-right {\n",
    "        background: #c2f2e9;\n",
    "        border-radius: 14px 14px 4px 14px;\n",
    "      }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    return style + f'<div class=\"chat-wrap\">{\"\".join(items) or \"<i>No debater messages found.</i>\"}</div>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc50b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_judge_md(final_state: Dict[str, Any]) -> str:\n",
    "    winner = (final_state.get(\"winner\") or \"\").strip() or \"draw\"\n",
    "    verdict = (final_state.get(\"verdict\") or \"\").strip() or \"No verdict provided.\"\n",
    "    return f\"### Judge's Decision\\n\\n**Winner:** `{winner}`\\n\\n**Verdict:**\\n\\n{verdict}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9a2f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debate_handler(question: str, max_rounds: int):\n",
    "    question = (question or \"\").strip()\n",
    "    if not question:\n",
    "        return \"<i>Please enter a question to start the debate.</i>\", \"### Judge's Decision\\n\\nAwaiting input.\"\n",
    "    try:\n",
    "        final_state = run_debate(question, max_rounds=max_rounds, print_result=False)\n",
    "    except Exception as e:\n",
    "        return f\"<b>Runtime error:</b> {html.escape(str(e))}\", \"### Judge's Decision\\n\\nAn error occurred.\"\n",
    "    transcript = coerce_messages(final_state)\n",
    "    entries = flatten_chat_messages(transcript)\n",
    "    chat_html = render_chat_html(entries)\n",
    "    judge_md = render_judge_md(final_state)\n",
    "    return chat_html, judge_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4579ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title=\"LangGraph Debate UI\") as demo:\n",
    "    gr.Markdown(\"# LangGraph Debate\\nEnter a question, then view debaters' chat-style responses.\")\n",
    "    with gr.Row():\n",
    "        question_in = gr.Textbox(label=\"Debate Question\", placeholder=\"e.g., Ask a question to discuss?\", lines=2)\n",
    "    with gr.Row():\n",
    "        rounds_in = gr.Slider(minimum=1, maximum=6, step=1, value=2, label=\"Rounds per Debater\")\n",
    "        run_btn = gr.Button(\"Run Debate\", variant=\"primary\")\n",
    "    with gr.Row():\n",
    "        debaters_out = gr.HTML(label=\"Debate Chat\")\n",
    "        judge_out = gr.Markdown(label=\"Judge\")\n",
    "    run_btn.click(fn=debate_handler, inputs=[question_in, rounds_in], outputs=[debaters_out, judge_out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37af9c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
